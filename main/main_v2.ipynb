{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/leo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/leo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/leo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') \n",
    "\n",
    "# IImporting dataset\n",
    "dataset = pd.read_csv(\"../data/AmazonData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset process function\n",
    "def dataset_process(dataset):\n",
    "\n",
    "    # Excluding columns that we dont use\n",
    "    cols = [0,2,3,5,6,8,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27]\n",
    "    dataset.drop(dataset.columns[cols], axis =1, inplace=True)\n",
    "    dataset.dropna(inplace = True)\n",
    "\n",
    "    # Splitting Category in 3 parts\n",
    "    new = dataset[\"Category\"].str.split(\"|\", n = 3, expand = True)\n",
    "    \n",
    "    # making the first category called Main Category\n",
    "    dataset[\"Main Category\"]= new[0] \n",
    "    \n",
    "    # making the second category called sub_category \n",
    "    dataset[\"Sub Category\"]= new[1]\n",
    "\n",
    "    # making the third category called side_category \n",
    "    dataset[\"Side Category\"]= new[2]\n",
    "\n",
    "    # making the last column consist of the remaining categories\n",
    "    dataset[\"Other Category\"]= new[3]\n",
    "\n",
    "    # Dropping old category columns and the remaining categories \n",
    "    dataset.drop(columns =[\"Category\"], inplace = True)\n",
    "\n",
    "    # Setting Column Selling Price as float value\n",
    "    # Database Price and weight treatment\n",
    "    dataset.rename(columns = {'Uniq Id':'Id','Shipping Weight':'Shipping Weight(Pounds)', 'Selling Price':'Selling Price($)'}, inplace = True)\n",
    "\n",
    "    # Removing units from Price and Weight\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.strip('ounces')\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.strip('pounds')\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].str.replace('$', '')\n",
    "\n",
    "    # Removing rows with Total Price invalid\n",
    "    indexes = dataset[dataset['Selling Price($)'] == 'Total price:'].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with '-' character\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].str.replace(',', '', regex=False)\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('-', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with '&' character\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('&', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with 'Currently' character\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('Currently', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with 'from' character\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('from', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Adjusting values with wrong format\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].str.split(' ').str[0]\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].astype(float)\n",
    "\n",
    "    # Setting Column Shipping Weight as float value\n",
    "    indexes = dataset[dataset['Shipping Weight(Pounds)'].str.contains(r'\\. ', na=False)].index\n",
    "\n",
    "    dataset.at[1619, 'Shipping Weight(Pounds)']\n",
    "    dataset.drop(1619, inplace=True)\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.replace(',', '', regex=False)\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].astype(float)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing text function\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('[^a-zA-Z]',' ').lower()\n",
    "    stop_re = '\\\\b'+'\\\\b|\\\\b'.join(nltk.corpus.stopwords.words('english'))+'\\\\b'\n",
    "    text = text.replace(stop_re, '')\n",
    "    text = text.split()\n",
    "\n",
    "    # Add lemmatization using WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Word2Vec model with a vector size of 100, using the 'Processed Product Name' column.\n",
    "def train_word2vec_model(dataset):\n",
    "    model = Word2Vec(sentences=dataset[\"Processed Product Name\"], vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing text function\n",
    "def vectorize_product(product_name, model):\n",
    "\n",
    "    words = [word for word in product_name if word in model.wv]\n",
    "    if len(words) > 0:\n",
    "        return np.mean([model.wv[word] for word in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.wv.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Recommendation function\n",
    "def product_recommendation(product_vector, dataset, top_n=5):\n",
    "    \n",
    "    # Calcular similaridades cosseno\n",
    "    similarities = dataset[\"Product Vector\"].apply(lambda x: cosine_similarity([product_vector], [x])[0][0])\n",
    "    \n",
    "    # Ordenar por similaridade e pegar os top_n produtos\n",
    "    top_indices = similarities.nlargest(top_n).index\n",
    "    \n",
    "    # Retornar o DataFrame com os produtos recomendados, mas mantendo os nomes originais\n",
    "    return dataset.loc[top_indices, dataset.columns != 'Product Vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Filter \n",
    "def category_filter(dataset, selected_product):\n",
    "\n",
    "    main_category_input = selected_product['Main Category']\n",
    "    sub_category_input = selected_product['Sub Category']\n",
    "    side_category_input = selected_product['Side Category']\n",
    "    other_category_input = selected_product['Other Category']\n",
    "\n",
    "    # Create a new column to calculate the score\n",
    "    dataset['score'] = 0\n",
    "\n",
    "    # Raises the score if categories match\n",
    "    dataset.loc[dataset['Main Category'] == main_category_input, 'score'] += 1\n",
    "    dataset.loc[dataset['Sub Category'] == sub_category_input, 'score'] += 1\n",
    "    dataset.loc[dataset['Side Category'] == side_category_input, 'score'] += 1\n",
    "    dataset.loc[dataset['Other Category'] == other_category_input, 'score'] += 1\n",
    "\n",
    "    # Sort the database based on the score\n",
    "    category_filter = dataset.sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Removes the new column\n",
    "    category_filter = category_filter.drop(columns='score')\n",
    "\n",
    "    # return the sorted database\n",
    "    if category_filter.empty:\n",
    "        print('No recommendaation found for this product.')\n",
    "    else:\n",
    "        return category_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def name_based_filter(dataset, product_name):\n",
    "\n",
    "    # Applying text preprocess in dataset\n",
    "    dataset[\"Processed Product Name\"] = dataset[\"Product Name\"].apply(preprocess_text)\n",
    "\n",
    "    model = train_word2vec_model(dataset)\n",
    "\n",
    "    # Applying vectorizing function in dataset\n",
    "    dataset[\"Product Vector\"] = dataset[\"Processed Product Name\"].apply(lambda x: vectorize_product(x, model))\n",
    "\n",
    "    # Pré-processando o nome do produto fornecido pelo usuário\n",
    "    processed_product_name = preprocess_text(product_name)\n",
    "\n",
    "    # Vetorizando o nome do produto fornecido (passar o modelo aqui também)\n",
    "    product_vector = vectorize_product(processed_product_name, model)\n",
    "\n",
    "    recommendation = product_recommendation(product_vector, dataset, top_n=5)\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7136 entries, 0 to 10001\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Product Name             7136 non-null   object \n",
      " 1   Selling Price($)         7136 non-null   float64\n",
      " 2   About Product            7136 non-null   object \n",
      " 3   Product Specification    7136 non-null   object \n",
      " 4   Shipping Weight(Pounds)  7136 non-null   float64\n",
      " 5   Main Category            7136 non-null   object \n",
      " 6   Sub Category             7136 non-null   object \n",
      " 7   Side Category            6155 non-null   object \n",
      " 8   Other Category           2724 non-null   object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 557.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/tcc/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_process(dataset)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select option:\n",
      "1- Select input from database\n",
      "2- Type product name\n",
      "                                 Product Name  Selling Price($)  \\\n",
      "9784         LEGO Round Storage Box 1, Yellow              9.89   \n",
      "1035              LEGO Lunch Box, Medium Pink             11.29   \n",
      "3940           LEGO Round Storage Box 1, Blue             11.92   \n",
      "6287  LEGO Ninjago Movie Lunchbox, Sand Green              6.00   \n",
      "4965                 LEGO Desk Drawer 8, Grey             17.99   \n",
      "\n",
      "                                          About Product  \\\n",
      "9784  Make sure this fits by entering your model num...   \n",
      "1035  Make sure this fits by entering your model num...   \n",
      "3940  Make sure this fits by entering your model num...   \n",
      "6287  Make sure this fits by entering your model num...   \n",
      "4965  Make sure this fits by entering your model num...   \n",
      "\n",
      "                                  Product Specification  \\\n",
      "9784  ProductDimensions:4.8x4.8x7.2inches|ItemWeight...   \n",
      "1035  ProductDimensions:7.8x3.9x3inches|ItemWeight:7...   \n",
      "3940  ProductDimensions:4.8x4.8x7.2inches|ItemWeight...   \n",
      "6287  ProductDimensions:6.3x5.5x2.6inches|ItemWeight...   \n",
      "4965  ProductDimensions:12.4x6.2x4.5inches|ItemWeigh...   \n",
      "\n",
      "      Shipping Weight(Pounds)    Main Category  \\\n",
      "9784                     8.50    Toys & Games    \n",
      "1035                     7.20  Home & Kitchen    \n",
      "3940                     7.00    Toys & Games    \n",
      "6287                     5.40  Home & Kitchen    \n",
      "4965                     1.57    Toys & Games    \n",
      "\n",
      "                            Sub Category             Side Category  \\\n",
      "9784    Kids' Furniture, Décor & Storage                      None   \n",
      "1035                   Kitchen & Dining    Storage & Organization    \n",
      "3940    Kids' Furniture, Décor & Storage                      None   \n",
      "6287                   Kitchen & Dining    Storage & Organization    \n",
      "4965   Kids' Furniture, Décor & Storage       Toy Chests & Storage   \n",
      "\n",
      "                                     Other Category  \\\n",
      "9784                                           None   \n",
      "1035   Travel & To-Go Food Containers | Lunch Boxes   \n",
      "3940                                           None   \n",
      "6287    Travel & To-Go Food Containers | Lunch Bags   \n",
      "4965                                           None   \n",
      "\n",
      "                              Processed Product Name  \n",
      "9784         [lego, round, storage, box, 1,, yellow]  \n",
      "1035               [lego, lunch, box,, medium, pink]  \n",
      "3940           [lego, round, storage, box, 1,, blue]  \n",
      "6287  [lego, ninjago, movie, lunchbox,, sand, green]  \n",
      "4965                  [lego, desk, drawer, 8,, grey]  \n",
      "\n",
      "\n",
      "lego\n",
      "Main Category not found in the database.\n",
      "Subcategoria not found in the database.\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Please select option:\")\n",
    "print(\"1- Select input from database\")\n",
    "print(\"2- Type product name\")\n",
    "user_input = int(input(\"Enter 1 or 2: \"))\n",
    "\n",
    "main_category_input = None\n",
    "sub_category_input = None\n",
    "side_category_input = None\n",
    "other_category_input = None\n",
    "\n",
    "if user_input == 1:\n",
    "    product_line = int(input(\"Type the product's number: \"))\n",
    "    product_line = product_line - 2\n",
    "\n",
    "    if 0 <= product_line < len(dataset):\n",
    "        selected_product = dataset.iloc[product_line]  # Selects the product by its line in the database\n",
    "        print(\"\\nSelected Product:\")\n",
    "        print(selected_product)\n",
    "    else:\n",
    "        print(\"Invalid line Number.\")\n",
    "    \n",
    "    product_name = selected_product['Product Name']\n",
    "\n",
    "    category_filter = category_filter(dataset, selected_product)\n",
    "    print(category_filter)\n",
    "    \n",
    "elif user_input == 2:\n",
    "    product_name = input(\"Type the product's name: \")\n",
    "    name_based_filter = name_based_filter(dataset, product_name)\n",
    "    print(name_based_filter)\n",
    "\n",
    "else:\n",
    "    print(\"Not a valid number\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(product_name)\n",
    "# Checking if categories are valid\n",
    "if main_category_input not in dataset['Main Category'].unique():\n",
    "    print('Main Category not found in the database.')\n",
    "else:\n",
    "    print(main_category_input)\n",
    "if sub_category_input not in dataset['Sub Category'].unique():\n",
    "    print('Subcategoria not found in the database.')\n",
    "else:\n",
    "    print(sub_category_input)\n",
    "if side_category_input not in dataset['Side Category'].unique():\n",
    "    print('Side Category not found in the database.')\n",
    "else:\n",
    "    print(side_category_input)\n",
    "if other_category_input not in dataset['Other Category'].unique():\n",
    "    print('Other Category not found in the database.')\n",
    "else:\n",
    "    print(other_category_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
