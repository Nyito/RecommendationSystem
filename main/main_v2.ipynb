{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/leo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/leo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/leo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') \n",
    "\n",
    "# IImporting dataset\n",
    "dataset = pd.read_csv(\"../data/AmazonData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset process function\n",
    "def dataset_process(dataset):\n",
    "\n",
    "    # Excluding columns that we dont use\n",
    "    cols = [0,2,3,5,6,8,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27]\n",
    "    dataset.drop(dataset.columns[cols], axis =1, inplace=True)\n",
    "    dataset.dropna(inplace = True)\n",
    "\n",
    "    # Splitting Category in 3 parts\n",
    "    new = dataset[\"Category\"].str.split(\"|\", n = 3, expand = True)\n",
    "    \n",
    "    # making the first category called Main Category\n",
    "    dataset[\"Main Category\"]= new[0] \n",
    "    \n",
    "    # making the second category called sub_category \n",
    "    dataset[\"Sub Category\"]= new[1]\n",
    "\n",
    "    # making the third category called side_category \n",
    "    dataset[\"Side Category\"]= new[2]\n",
    "\n",
    "    # making the last column consist of the remaining categories\n",
    "    dataset[\"Other Category\"]= new[3]\n",
    "\n",
    "    # Dropping old category columns and the remaining categories \n",
    "    dataset.drop(columns =[\"Category\"], inplace = True)\n",
    "\n",
    "    # Setting Column Selling Price as float value\n",
    "    # Database Price and weight treatment\n",
    "    dataset.rename(columns = {'Uniq Id':'Id','Shipping Weight':'Shipping Weight(Pounds)', 'Selling Price':'Selling Price($)'}, inplace = True)\n",
    "\n",
    "    # Removing units from Price and Weight\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.strip('ounces')\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.strip('pounds')\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].str.replace('$', '')\n",
    "\n",
    "    # Removing rows with Total Price invalid\n",
    "    indexes = dataset[dataset['Selling Price($)'] == 'Total price:'].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with '-' character\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].str.replace(',', '', regex=False)\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('-', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with '&' character\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('&', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with 'Currently' character\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('Currently', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Removing rows with 'from' character\n",
    "    indexes = dataset[dataset['Selling Price($)'].str.contains('from', na=False)].index\n",
    "    dataset.drop(indexes, inplace=True)\n",
    "\n",
    "    # Adjusting values with wrong format\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].str.split(' ').str[0]\n",
    "    dataset['Selling Price($)'] = dataset['Selling Price($)'].astype(float)\n",
    "\n",
    "    # Setting Column Shipping Weight as float value\n",
    "    indexes = dataset[dataset['Shipping Weight(Pounds)'].str.contains(r'\\. ', na=False)].index\n",
    "\n",
    "    dataset.at[1619, 'Shipping Weight(Pounds)']\n",
    "    dataset.drop(1619, inplace=True)\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.replace(',', '', regex=False)\n",
    "    dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].astype(float)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing text function\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('[^a-zA-Z]',' ').lower()\n",
    "    stop_re = '\\\\b'+'\\\\b|\\\\b'.join(nltk.corpus.stopwords.words('english'))+'\\\\b'\n",
    "    text = text.replace(stop_re, '')\n",
    "    text = text.split()\n",
    "\n",
    "    # Add lemmatization using WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Word2Vec model with a vector size of 100, using the 'Processed Product Name' column.\n",
    "def train_word2vec_model(dataset):\n",
    "    model = Word2Vec(sentences=dataset[\"Processed Product Name\"], vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing text function\n",
    "def vectorize_product(product_name, model):\n",
    "\n",
    "    words = [word for word in product_name if word in model.wv]\n",
    "    if len(words) > 0:\n",
    "        return np.mean([model.wv[word] for word in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.wv.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Recommendation function\n",
    "def product_recommendation(product_vector, dataset, top_n=5):\n",
    "    \n",
    "    # Calcular similaridades cosseno\n",
    "    similarities = dataset[\"Product Vector\"].apply(lambda x: cosine_similarity([product_vector], [x])[0][0])\n",
    "    \n",
    "    # Ordenar por similaridade e pegar os top_n produtos\n",
    "    top_indices = similarities.nlargest(top_n).index\n",
    "    \n",
    "    # Retornar o DataFrame com os produtos recomendados, mas mantendo os nomes originais\n",
    "    return dataset.loc[top_indices, dataset.columns != 'Product Vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Filter \n",
    "def category_filter(dataset, selected_product):\n",
    "\n",
    "    main_category_input = selected_product['Main Category']\n",
    "    sub_category_input = selected_product['Sub Category']\n",
    "    side_category_input = selected_product['Side Category']\n",
    "    other_category_input = selected_product['Other Category']\n",
    "\n",
    "    # Create a new column to calculate the score\n",
    "    dataset['score'] = 0\n",
    "\n",
    "    # Raises the score if categories match\n",
    "    dataset.loc[dataset['Main Category'] == main_category_input, 'score'] += 1\n",
    "    dataset.loc[dataset['Sub Category'] == sub_category_input, 'score'] += 1\n",
    "    dataset.loc[dataset['Side Category'] == side_category_input, 'score'] += 1\n",
    "    dataset.loc[dataset['Other Category'] == other_category_input, 'score'] += 1\n",
    "\n",
    "    # Sort the database based on the score\n",
    "    category_filter = dataset.sort_values(by='score', ascending=False)\n",
    "\n",
    "    # Remove products with score < 1\n",
    "    category_filter = category_filter[category_filter['score'] > 1]\n",
    "\n",
    "    # Removes the new column\n",
    "    category_filter = category_filter.drop(columns='score')\n",
    "\n",
    "    # return the sorted database\n",
    "    if category_filter.empty:\n",
    "        print('No recommendaation found for this product.')\n",
    "    else:\n",
    "        return category_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def name_based_filter(dataset, product_name):\n",
    "\n",
    "    # Applying text preprocess in dataset\n",
    "    dataset[\"Processed Product Name\"] = dataset[\"Product Name\"].apply(preprocess_text)\n",
    "\n",
    "    model = train_word2vec_model(dataset)\n",
    "\n",
    "    # Applying vectorizing function in dataset\n",
    "    dataset[\"Product Vector\"] = dataset[\"Processed Product Name\"].apply(lambda x: vectorize_product(x, model))\n",
    "\n",
    "    # Pré-processando o nome do produto fornecido pelo usuário\n",
    "    processed_product_name = preprocess_text(product_name)\n",
    "\n",
    "    # Vetorizando o nome do produto fornecido (passar o modelo aqui também)\n",
    "    product_vector = vectorize_product(processed_product_name, model)\n",
    "\n",
    "    recommendation = product_recommendation(product_vector, dataset, top_n=5)\n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7136 entries, 0 to 10001\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Product Name             7136 non-null   object \n",
      " 1   Selling Price($)         7136 non-null   float64\n",
      " 2   About Product            7136 non-null   object \n",
      " 3   Product Specification    7136 non-null   object \n",
      " 4   Shipping Weight(Pounds)  7136 non-null   float64\n",
      " 5   Main Category            7136 non-null   object \n",
      " 6   Sub Category             7136 non-null   object \n",
      " 7   Side Category            6155 non-null   object \n",
      " 8   Other Category           2724 non-null   object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 557.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/tcc/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_process(dataset)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select option:\n",
      "1- Select input from database\n",
      "2- Type product name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Product:\n",
      "Product Name               LEGO Minecraft Creeper BigFig and Ocelot Chara...\n",
      "Selling Price($)                                                       14.99\n",
      "About Product              Make sure this fits by entering your model num...\n",
      "Product Specification      ProductDimensions:5.5x7.5x1.8inches|ItemWeight...\n",
      "Shipping Weight(Pounds)                                                  5.6\n",
      "Main Category                                                  Toys & Games \n",
      "Sub Category                                                  Building Toys \n",
      "Side Category                                                  Building Sets\n",
      "Other Category                                                          None\n",
      "Name: 13, dtype: object\n",
      "                                           Product Name  Selling Price($)  \\\n",
      "13    LEGO Minecraft Creeper BigFig and Ocelot Chara...             14.99   \n",
      "6051  LEGO Minecraft The Panda Nursery 21158 Constru...             19.99   \n",
      "920   LEGO Star Wars Resistance Y-Wing Microfighter ...              9.90   \n",
      "1498  K'NEX Thrill Rides – Cobweb Curse Roller Coast...             27.82   \n",
      "8164  Quercetti Big Marbledrome Marble Run Toy for A...             33.91   \n",
      "\n",
      "                                          About Product  \\\n",
      "13    Make sure this fits by entering your model num...   \n",
      "6051  Make sure this fits by entering your model num...   \n",
      "920   Make sure this fits by entering your model num...   \n",
      "1498  Make sure this fits by entering your model num...   \n",
      "8164  Make sure this fits by entering your model num...   \n",
      "\n",
      "                                  Product Specification  \\\n",
      "13    ProductDimensions:5.5x7.5x1.8inches|ItemWeight...   \n",
      "6051  ProductDimensions:10.3x7.5x2.4inches|ItemWeigh...   \n",
      "920   ProductDimensions:5.5x4.8x1.8inches|ItemWeight...   \n",
      "1498  ProductDimensions:16x2.5x14inches|ItemWeight:1...   \n",
      "8164  ProductDimensions:15.8x13.4x3.5inches|ItemWeig...   \n",
      "\n",
      "      Shipping Weight(Pounds)  Main Category     Sub Category   Side Category  \\\n",
      "13                       5.60  Toys & Games    Building Toys    Building Sets   \n",
      "6051                    11.80  Toys & Games    Building Toys    Building Sets   \n",
      "920                      3.20  Toys & Games    Building Toys    Building Sets   \n",
      "1498                     2.20  Toys & Games    Building Toys    Building Sets   \n",
      "8164                     3.66  Toys & Games    Building Toys      Marble Runs   \n",
      "\n",
      "     Other Category                             Processed Product Name  \n",
      "13             None  [lego, minecraft, creeper, bigfig, and, ocelot...  \n",
      "6051           None  [lego, minecraft, the, panda, nursery, 21158, ...  \n",
      "920            None  [lego, star, war, resistance, y-wing, microfig...  \n",
      "1498           None  [k'nex, thrill, ride, –, cobweb, curse, roller...  \n",
      "8164           None  [quercetti, big, marbledrome, marble, run, toy...  \n",
      "\n",
      "\n",
      "LEGO Minecraft Creeper BigFig and Ocelot Characters 21156 Buildable Toy Minecraft Figure Gift Set for Play and Decoration, New 2020 (184 Pieces)\n",
      "Main Category not found in the database.\n",
      "Subcategoria not found in the database.\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Please select option:\")\n",
    "print(\"1- Select input from database\")\n",
    "print(\"2- Type product name\")\n",
    "user_input = int(input(\"Enter 1 or 2: \"))\n",
    "\n",
    "main_category_input = None\n",
    "sub_category_input = None\n",
    "side_category_input = None\n",
    "other_category_input = None\n",
    "\n",
    "if user_input == 1:\n",
    "    product_line = int(input(\"Type the product's number: \"))\n",
    "    product_line = product_line - 2\n",
    "\n",
    "    if 0 <= product_line < len(dataset):\n",
    "        selected_product = dataset.iloc[product_line]  # Selects the product by its line in the database\n",
    "        print(\"\\nSelected Product:\")\n",
    "        print(selected_product)\n",
    "    else:\n",
    "        print(\"Invalid line Number.\")\n",
    "    \n",
    "    product_name = selected_product['Product Name']\n",
    "\n",
    "    category_filter = category_filter(dataset, selected_product)\n",
    "    # print(category_filter)\n",
    "\n",
    "    name_based_filter = name_based_filter(category_filter, product_name)\n",
    "    print(name_based_filter)\n",
    "    \n",
    "elif user_input == 2:\n",
    "    product_name = input(\"Type the product's name: \")\n",
    "    name_based_filter = name_based_filter(dataset, product_name)\n",
    "    print(name_based_filter)\n",
    "\n",
    "else:\n",
    "    print(\"Not a valid number\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(product_name)\n",
    "# Checking if categories are valid\n",
    "if main_category_input not in dataset['Main Category'].unique():\n",
    "    print('Main Category not found in the database.')\n",
    "else:\n",
    "    print(main_category_input)\n",
    "if sub_category_input not in dataset['Sub Category'].unique():\n",
    "    print('Subcategoria not found in the database.')\n",
    "else:\n",
    "    print(sub_category_input)\n",
    "if side_category_input not in dataset['Side Category'].unique():\n",
    "    print('Side Category not found in the database.')\n",
    "else:\n",
    "    print(side_category_input)\n",
    "if other_category_input not in dataset['Other Category'].unique():\n",
    "    print('Other Category not found in the database.')\n",
    "else:\n",
    "    print(other_category_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
