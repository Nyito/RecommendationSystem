{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ricar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ricar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\ricar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7216 entries, 0 to 10001\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Product Name           7216 non-null   object\n",
      " 1   Category               7216 non-null   object\n",
      " 2   Selling Price          7216 non-null   object\n",
      " 3   About Product          7216 non-null   object\n",
      " 4   Product Specification  7216 non-null   object\n",
      " 5   Shipping Weight        7216 non-null   object\n",
      " 6   Main Category          7216 non-null   object\n",
      " 7   Sub-Category           7216 non-null   object\n",
      " 8   Side Category          6231 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 563.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') \n",
    "\n",
    "dataset = pd.read_csv(\"AmazonData.csv\")\n",
    "\n",
    "# Excluding columns that we dont use\n",
    "cols = [0,2,3,5,6,8,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27]\n",
    "dataset.drop(dataset.columns[cols], axis =1, inplace=True)\n",
    "dataset.dropna(inplace = True)\n",
    "\n",
    "# Splitting Category in 3 parts\n",
    "new = dataset[\"Category\"].str.split(\"|\", n = 2, expand = True)\n",
    "  \n",
    "# making the first category called Main Category\n",
    "dataset[\"Main Category\"]= new[0] \n",
    "  \n",
    "# making the second category called sub_category \n",
    "dataset[\"Sub-Category\"]= new[1]\n",
    "\n",
    "# making the third category called side_category \n",
    "dataset[\"Side Category\"]= new[2]\n",
    "\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7137 entries, 0 to 10001\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Product Name             7137 non-null   object \n",
      " 1   Category                 7137 non-null   object \n",
      " 2   Selling Price($)         7137 non-null   float64\n",
      " 3   About Product            7137 non-null   object \n",
      " 4   Product Specification    7137 non-null   object \n",
      " 5   Shipping Weight(Pounds)  7137 non-null   object \n",
      " 6   Main Category            7137 non-null   object \n",
      " 7   Sub-Category             7137 non-null   object \n",
      " 8   Side Category            6155 non-null   object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 557.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Setting Column Selling Price as float value\n",
    "# Database Price and weight treatment\n",
    "dataset.rename(columns = {'Uniq Id':'Id','Shipping Weight':'Shipping Weight(Pounds)', 'Selling Price':'Selling Price($)'}, inplace = True)\n",
    "\n",
    "# Removing units from Price and Weight\n",
    "dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.strip('ounces')\n",
    "dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.strip('pounds')\n",
    "dataset['Selling Price($)'] = dataset['Selling Price($)'].str.replace('$', '')\n",
    "\n",
    "# Removing rows with Total Price invalid\n",
    "indexes = dataset[dataset['Selling Price($)'] == 'Total price:'].index\n",
    "dataset.drop(indexes, inplace=True)\n",
    "\n",
    "# Removing rows with '-' character\n",
    "dataset['Selling Price($)'] = dataset['Selling Price($)'].str.replace(',', '', regex=False)\n",
    "indexes = dataset[dataset['Selling Price($)'].str.contains('-', na=False)].index\n",
    "dataset.drop(indexes, inplace=True)\n",
    "\n",
    "# Removing rows with '&' character\n",
    "indexes = dataset[dataset['Selling Price($)'].str.contains('&', na=False)].index\n",
    "dataset.drop(indexes, inplace=True)\n",
    "\n",
    "# Removing rows with 'Currently' character\n",
    "indexes = dataset[dataset['Selling Price($)'].str.contains('Currently', na=False)].index\n",
    "dataset.drop(indexes, inplace=True)\n",
    "\n",
    "# Removing rows with 'from' character\n",
    "indexes = dataset[dataset['Selling Price($)'].str.contains('from', na=False)].index\n",
    "dataset.drop(indexes, inplace=True)\n",
    "\n",
    "# Adjusting values with wrong format\n",
    "dataset['Selling Price($)'] = dataset['Selling Price($)'].str.split(' ').str[0]\n",
    "dataset['Selling Price($)'] = dataset['Selling Price($)'].astype(float)\n",
    "\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7136 entries, 0 to 10001\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Product Name             7136 non-null   object \n",
      " 1   Category                 7136 non-null   object \n",
      " 2   Selling Price($)         7136 non-null   float64\n",
      " 3   About Product            7136 non-null   object \n",
      " 4   Product Specification    7136 non-null   object \n",
      " 5   Shipping Weight(Pounds)  7136 non-null   float64\n",
      " 6   Main Category            7136 non-null   object \n",
      " 7   Sub-Category             7136 non-null   object \n",
      " 8   Side Category            6155 non-null   object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 557.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Setting Column Shipping Weight as float value\n",
    "indexes = dataset[dataset['Shipping Weight(Pounds)'].str.contains(r'\\. ', na=False)].index\n",
    "\n",
    "dataset.at[1619, 'Shipping Weight(Pounds)']\n",
    "dataset.drop(1619, inplace=True)\n",
    "dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].str.replace(',', '', regex=False)\n",
    "dataset['Shipping Weight(Pounds)'] = dataset['Shipping Weight(Pounds)'].astype(float)\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of lemmatization\n",
    "def preprocessamento(texto):\n",
    "    texto = texto.replace('[^a-zA-Z]',' ').lower()\n",
    "    stop_re = '\\\\b'+'\\\\b|\\\\b'.join(nltk.corpus.stopwords.words('english'))+'\\\\b'\n",
    "    texto = texto.replace(stop_re, '')\n",
    "    texto = texto.split()\n",
    "\n",
    "    # Add lemmatization using WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in texto]\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [db, longboards, coreflex, crossbow, 41\", bamb...\n",
       "1        [electronic, snap, circuit, mini, kit, classpa...\n",
       "2        [3doodler, create, flexy, 3d, printing, filame...\n",
       "3        [guillow, airplane, design, studio, with, trav...\n",
       "4                   [woodstock-, collage, 500, pc, puzzle]\n",
       "                               ...                        \n",
       "9995     [cozy, line, home, fashion, size, 2, piece, oc...\n",
       "9996           [lego, 8-brick, storage, box,, bright, red]\n",
       "9998     [trend, international, nfl, la, charger, hg, -...\n",
       "9999     [newpath, learning, 10, piece, science, owl, a...\n",
       "10001    [hasegawa, ladder, lucano, step, ladder,, orange]\n",
       "Name: Processed Product Name, Length: 7136, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess with lemmatization\n",
    "dataset[\"Processed Product Name\"] = dataset[\"Product Name\"].apply(preprocessamento)\n",
    "dataset[\"Processed Product Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-0.0062452788, 0.029205084, 0.013634283, 0.01...\n",
       "1        [-0.020676203, 0.15442109, 0.053754345, 0.1054...\n",
       "2        [-0.018686125, 0.13685417, 0.044907585, 0.0983...\n",
       "3        [-0.0619574, 0.26906204, 0.09278533, 0.1580728...\n",
       "4        [-0.023948986, 0.16697064, 0.046132583, 0.1102...\n",
       "                               ...                        \n",
       "9995     [-0.040653158, 0.21899302, 0.07272695, 0.15713...\n",
       "9996     [-0.024467006, 0.16234973, 0.060247432, 0.1109...\n",
       "9998     [-0.031669613, 0.1703979, 0.048933074, 0.12644...\n",
       "9999     [-0.03083203, 0.20535116, 0.06601711, 0.155057...\n",
       "10001    [-0.004292644, 0.041014943, 0.017365305, 0.029...\n",
       "Name: Product Vector, Length: 7136, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inicio do modelo de recomendacao\n",
    "modelo = Word2Vec(sentences=dataset[\"Processed Product Name\"], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def vectorize_product(product_name):\n",
    "    words = [word for word in product_name if word in modelo.wv]\n",
    "    if len(words) > 0:\n",
    "        return np.mean([modelo.wv[word] for word in words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(modelo.wv.vector_size)\n",
    "    \n",
    "dataset[\"Product Vector\"] = dataset[\"Processed Product Name\"].apply(vectorize_product)\n",
    "dataset[\"Product Vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_produtos(input_text, top_n=5):\n",
    "    # Pré-processar a entrada do usuário\n",
    "    input_text_processed = preprocessamento(input_text)\n",
    "    \n",
    "    # Gerar vetor para a entrada\n",
    "    input_vector = vectorize_product(input_text_processed)\n",
    "    \n",
    "    # Calcular similaridades cosseno\n",
    "    similarities = dataset[\"Product Vector\"].apply(lambda x: cosine_similarity([input_vector], [x])[0][0])\n",
    "    \n",
    "    # Ordenar por similaridade e pegar os top_n produtos\n",
    "    top_indices = similarities.nlargest(top_n).index\n",
    "    \n",
    "    # Retornar o DataFrame com os produtos recomendados, mas mantendo os nomes originais\n",
    "    return dataset.loc[top_indices, dataset.columns != 'Product Vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input(\"Digite o nome do produto: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Product Name  \\\n",
      "2762                    Foil Snowflake Danglers (2/Pkg)   \n",
      "2305                 Plaid Hat Pandemic: Rapid Response   \n",
      "1313                             Lemming 7\" (Item 4707)   \n",
      "4910  Sunstaches Marvel Avengers Hulk Character Sung...   \n",
      "370                    Marvel Hulk Fist Pewter Key Ring   \n",
      "\n",
      "                                               Category  Selling Price($)  \\\n",
      "2762       Toys & Games | Party Supplies | Party Favors             13.35   \n",
      "2305   Toys & Games | Games & Accessories | Board Games             34.34   \n",
      "1313  Toys & Games | Stuffed Animals & Plush Toys | ...             21.75   \n",
      "4910  Clothing, Shoes & Jewelry | Costumes & Accesso...              8.98   \n",
      "370   Toys & Games | Collectible Toys | Collectible ...              5.51   \n",
      "\n",
      "                                          About Product  \\\n",
      "2762  Make sure this fits by entering your model num...   \n",
      "2305  Make sure this fits by entering your model num...   \n",
      "1313  Make sure this fits by entering your model num...   \n",
      "4910  Make sure this fits by entering your model num...   \n",
      "370   Made of pewter | Opp bag with backer card pack...   \n",
      "\n",
      "                                  Product Specification  \\\n",
      "2762  ProductDimensions:9.5x7x1inches|ItemWeight:0.3...   \n",
      "2305  ProductDimensions:12x8.9x1.8inches|ItemWeight:...   \n",
      "1313  ProductDimensions:6.2x3.5x3.1inches|ItemWeight...   \n",
      "4910  ProductDimensions:7x6x6inches|ItemWeight:2.4ou...   \n",
      "370   ProductDimensions:3x1.2x5.5inches|ItemWeight:3...   \n",
      "\n",
      "      Shipping Weight(Pounds)               Main Category  \\\n",
      "2762                     0.32               Toys & Games    \n",
      "2305                     2.20               Toys & Games    \n",
      "1313                     1.44               Toys & Games    \n",
      "4910                     3.20  Clothing, Shoes & Jewelry    \n",
      "370                      3.20               Toys & Games    \n",
      "\n",
      "                        Sub-Category  \\\n",
      "2762                 Party Supplies    \n",
      "2305            Games & Accessories    \n",
      "1313   Stuffed Animals & Plush Toys    \n",
      "4910         Costumes & Accessories    \n",
      "370                Collectible Toys    \n",
      "\n",
      "                                          Side Category  \\\n",
      "2762                                       Party Favors   \n",
      "2305                                        Board Games   \n",
      "1313                      Stuffed Animals & Teddy Bears   \n",
      "4910                   Kids & Baby | Boys | Accessories   \n",
      "370    Collectible Display & Storage | Display Cases...   \n",
      "\n",
      "                                 Processed Product Name  \n",
      "2762               [foil, snowflake, danglers, (2/pkg)]  \n",
      "2305           [plaid, hat, pandemic:, rapid, response]  \n",
      "1313                        [lemming, 7\", (item, 4707)]  \n",
      "4910  [sunstaches, marvel, avenger, hulk, character,...  \n",
      "370             [marvel, hulk, fist, pewter, key, ring]  \n"
     ]
    }
   ],
   "source": [
    "recomendacoes = recomendar_produtos(input_text, top_n=5)\n",
    "print(recomendacoes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
